# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя

**Ответ:**

Если это операция на чтение, то при помощи `$currentOp` находим нужный `operation id`:
```shell
use admin
db.aggregate( [
   { $currentOp : { allUsers: true, localOps: true } },
   { $match : <filter condition> } 
] )
```
Для которого вызываем:
```
db.killOp(<opid of the query to kill>)
```
Если это операция на запись, то аналогично вызываем `$currentOp`. 
Если данная операция на запись ассоциирована с сессией, то выполняем поиск `lsid` (logical session id).
Затем, используя `lsid`, вызываем `killSessions`:
```shell
db.adminCommand( { killSessions: [
   { "id" : UUID("80e48c5a-f7fb-4541-8ac0-9e3a1ed224a4"), "uid" : BinData(0,"47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=") }
] } )
```
Если данная операция на запись не ассоциирована с сессией, то необходимо будет найти и убить операцию на всех шардах.
То есть, при помощи `$currentOp` находим шарды и `operation id`, затем вызываем `db.killOp()`:
```shell
db.killOp("shardB:79014");
db.killOp("shardA:100813");
```

- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

**Ответ:**

Если есть вероятность, что запрос зависнет, то можно применить метод `maxTimeMS()`.
Данный метод устанавливает временной лимит на выполнение запроса или команды. Когда запрос достигает этого лимита,
то MongoDB прерывает запрос. 

Пример для 30мс:
```shell
db.location.find( { "town": { "$regex": "(Pine Lumber)",
                              "$options": 'i' } } ).maxTimeMS(30)
```


## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

**Ответ:**
Если стало увеличиваться отношение количества записанных key-value значений к количеству истекших значений, 
то вероятно Redis не успевает удалять истекшие значения. В результате роста истекших значений, которые необходимо удалить,
Redis может уйти в блокировку и зациклиться на их удалении пока в выборке не будет менее 25% истекших записей.

 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

**Ответ:**
Возможно есть какие-то проблемы на уровне сети. 
Первым делом необходимо исследовать есть ли потери сетевых пакетов между клиентом и сервером и устранить их.
Если проблема сохранилась, то необходимо проверить достаточно ли быстрое сетевое соединение между клиентом и сервером.
Если скорость сети между клиентом и сервером MySQL недостаточно быстрая - в этом случае
может сработать таймаут при чтении запроса от клиента `net_read_timeout`. 
Если сеть медленная и запрос возвращает очень много данных, то возможно срабатывает таймаут 
отправки результата клиенту `net_write_timeout`.


Какие пути решения данной проблемы вы можете предложить?

**Ответ:**
Обеспечить надежное сетевое соединение.
Клиент, на уровне сессии с БД, может попробовать увеличить `net_write_timeout` или `net_read_timeout`.

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

**Ответ:**

Судя по ошибке, в системе был вызван процесс Out-Of-Memory Killer.
Это значит, что в системе возникла нехватка оперативной памяти.

Как бы вы решили данную проблему?

**Ответ:**
 1. Необходимо выяснить какой процесс или приложение спровоцировало нехватку памяти: 
 - если найденный процесс не связан с БД, то вероятно он лишний на сервере и нужно его отключить;
 - если посторонних процессов не найдено, то требуется оптимизация потребления памяти внутри БД и/или увеличение памяти RAM на сервере.

 2. В целях оптимизации потребления памяти внутри БД нужно:
 - проверить параметр `shared_buffers` - он должен быть равен примерно 1/4 от общего количества памяти на сервере;
 - проверить, возможно какой-то клиент выставляет высокий `work_mem` и запускает сложный запрос, который "съедает" большую часть памяти - в этом случае может
помочь оптимизация запроса или выделение для клиента отдельного сервера;
 - проверить, возможно стоит слишком высокое значение `max_connections` и клиентские соединения занимают всю доступную память - в этом случае
поможет уменьшение параметра `max_connections` до оптимального фиксированного значения, настройка мультиплексора `pgbouncer` в режиме `Transaction Pooling` и
переключение всех клиентов на `pgbouncer`.
 
---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
